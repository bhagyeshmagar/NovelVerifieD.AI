================================================================================
                    NOVELVERIFIED.AI - PROJECT DOCUMENTATION
                    NovelVerified.AI Team - NovelVerified.AI Pathway-based
================================================================================

LAST UPDATED: January 12, 2026

================================================================================
SECTION 1: QUICK START
================================================================================

PREREQUISITES:
- Python 3.10+
- Node.js 18+ (for frontend)
- Ollama (https://ollama.ai) with a model installed

INSTALLATION:
1. Extract the ZIP file
2. Run setup script:
   chmod +x setup.sh
   ./setup.sh

3. Or manually:
   pip install -r requirements.txt
   cd frontend && npm install && cd ..

RUNNING THE SYSTEM:
1. Start the Backend API:
   python flask_api/app.py

2. Start the Frontend Dashboard (new terminal):
   cd frontend && npm run dev
   > Open http://localhost:5173

3. Run Pipeline:
   Use the "Pipeline" tab in the Dashboard to Start/Stop/Monitor verification.
   Terminal 1: python flask_api/app.py
   Terminal 2: cd frontend && npm run dev
   Open: http://localhost:5173

================================================================================
SECTION 2: PROBLEM STATEMENT
================================================================================

TASK: Verify whether hypothetical character backstories are CONSISTENT or 
      CONTRADICTED by the actual novel text.

INPUT:
- Full novel text (100k+ words, no truncation)
- Hypothetical character backstory (early-life events, beliefs, motivations)

OUTPUT (results.csv):
- Story ID: Claim identifier
- Prediction: 1 (consistent) or 0 (contradicted)
- Rationale: Short explanation (1-2 lines)

TRACK A REQUIREMENTS:
1. MUST use Pathway framework for document processing ✓
2. CAN use any modeling approach (we use Ollama LLMs) ✓

================================================================================
SECTION 3: PROJECT STRUCTURE
================================================================================

NovelVerified_AI/
├── Data/                        # Source data
│   ├── In search of the castaways.txt
│   ├── The Count of Monte Cristo.txt
│   ├── train.csv                # Training claims with labels
│   └── test.csv                 # Test claims to verify
├── agents/                      # Pipeline agents (11 files)
│   ├── ingestion_agent.py       # Chunks novels (Pathway integration)
│   ├── embedding_agent.py       # Creates FAISS vector index
│   ├── claim_parser.py          # Parses CSV claims
│   ├── retriever_agent.py       # Temporal-aware RAG retrieval
│   ├── reasoning_agent.py       # Claude API reasoning
│   ├── reasoning_agent_local.py # Ollama local reasoning (4-stage)
│   ├── constraint_types.py      # Constraint type definitions
│   ├── dossier_writer.py        # Structured dossier generation
│   ├── results_aggregator.py    # Final CSV output
│   ├── pathway_store.py         # Pathway document store
│   └── utils.py                 # Shared utilities
├── flask_api/                   # Dashboard backend (6 files)
│   ├── app.py                   # Main API server
│   ├── claims.py                # Claims management
│   ├── history.py               # Run history
│   ├── pipeline.py              # Pipeline execution control
│   ├── pipeline_api.py          # Pipeline REST endpoints
│   └── upload.py                # File handling
├── frontend/                    # Modern React Dashboard
│   ├── src/                     # Source code
│   │   ├── components/          # Reusable UI components
│   │   ├── pages/               # Application pages (Dashboard, Pipeline, etc.)
│   │   └── services/            # API integration
│   ├── package.json             # NPM dependencies
│   └── vite.config.js           # Vite configuration
├── tests/                       # Unit tests
├── run_all.py                   # Pipeline orchestrator
├── setup.sh                     # Installation script
├── requirements.txt             # Python dependencies
├── README.md                    # Quick start guide
├── REPORT.md                    # Technical report
├── TRACK_A_JUSTIFICATION.md     # Pathway-based compliance
├── .env.example                 # Environment template
└── .gitignore                   # Git exclusions

GENERATED DIRECTORIES (after running pipeline):
├── chunks/                      # Chunked novel text (JSONL)
├── index/                       # FAISS index + metadata
├── claims/                      # Parsed claims (JSONL)
├── evidence/                    # Retrieved passages per claim
├── verdicts/                    # LLM verdicts (JSON)
├── dossiers/                    # Structured Markdown reports
├── pathway_store/               # Pathway document store
└── output/
    └── results.csv              # NovelVerified.AI submission format

================================================================================
SECTION 4: SYSTEM ARCHITECTURE
================================================================================

7-AGENT PIPELINE with ANTI-BIAS REASONING:

┌─────────────────────────────────────────────────────────────────────────────┐
│                              DATA SOURCES                                    │
├─────────────────────────────────────────────────────────────────────────────┤
│   Data/*.txt                  │         Data/train.csv & test.csv           │
│   (Full novel texts)          │         (Claims to verify)                  │
└─────────────────────┬─────────┴────────────────────┬────────────────────────┘
                      │                              │
                      ▼                              ▼
┌─────────────────────────────┐    ┌─────────────────────────────┐
│    AGENT 1: INGESTION       │    │    AGENT 3: CLAIM PARSER    │
│    - Uses Pathway framework │    │    - Reads train.csv/test.csv│
│    - Chunks novels          │    │    - Outputs claims.jsonl   │
│    - EARLY/MID/LATE tags    │    │                             │
└─────────────────────┬───────┘    └─────────────────┬───────────┘
                      │                              │
                      ▼                              │
┌─────────────────────────────┐                      │
│    AGENT 2: EMBEDDING       │                      │
│    - sentence-transformers  │                      │
│    - Creates FAISS index    │                      │
└─────────────────────┬───────┘                      │
                      │                              │
                      ▼                              ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                       AGENT 4: RETRIEVER                                     │
│    - Temporal-aware retrieval (EARLY/MID/LATE slices)                       │
│    - Counterfactual queries for contradiction-seeking                       │
└─────────────────────────────────────────────────────┬───────────────────────┘
                                                      │
                                                      ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                       AGENT 5: REASONING (4-STAGE PIPELINE)                  │
│                       (reasoning_agent_local.py - uses Ollama)               │
│                                                                              │
│    Stage 1: DECOMPOSE - Break claim into atomic sub-claims                  │
│    Stage 2: EVALUATE SUPPORT - Seek supporting evidence                     │
│    Stage 3: EVALUATE CONTRADICTION - Seek contradicting evidence (ANTI-BIAS)│
│    Stage 4: SYNTHESIZE - Calibrated verdict with thresholds                 │
└─────────────────────┬───────────────────────────────┬───────────────────────┘
                      │                               │
                      ▼                               ▼
┌─────────────────────────────┐    ┌─────────────────────────────┐
│    AGENT 6: DOSSIER         │    │    AGENT 7: AGGREGATOR      │
│    - Constraint-linked docs │    │    - NovelVerified.AI format CSV        │
│    - Temporal evidence      │    │    - Story ID, Prediction,  │
└─────────────────────────────┘    │      Rationale              │
                                   └─────────────────────────────┘

================================================================================
SECTION 5: HOW TO RUN
================================================================================

OPTION 1: Full Pipeline (Recommended)
--------------------------------------
python run_all.py --local --clean

OPTION 2: With Frontend Dashboard
----------------------------------
# Terminal 1: Start backend
python flask_api/app.py

# Terminal 2: Start frontend
cd frontend && npm run dev

# Open http://localhost:5173 and click "Run Pipeline"

OPTION 3: Run Specific Stage
-----------------------------
python run_all.py --start-from reasoning

================================================================================
SECTION 6: ANTI-BIAS REASONING (Key Innovation)
================================================================================

PROBLEM: LLMs tend to find supporting evidence even for false claims.

SOLUTION: Dual-Perspective Evaluation

1. SUPPORT-SEEKING PROMPT:
   "Actively search for evidence that SUPPORTS this claim..."
   
2. CONTRADICTION-SEEKING PROMPT:
   "Actively search for evidence that CONTRADICTS this claim..."

CALIBRATED THRESHOLDS:
- CONTRADICTION_THRESHOLD = 0.6 (High bar - hard to mark contradicted)
- STRONG_SUPPORT_THRESHOLD = 0.5 (Moderate bar for support)

This prevents both over-eager support AND over-eager contradiction.

================================================================================
SECTION 7: OUTPUT FORMAT (NovelVerified.AI Submission)
================================================================================

The results.csv file follows this format:

Story ID,Prediction,Rationale
95,1,Evidence confirms the claim about Villefort...
136,0,The backstory contradicts the novel's timeline...

Where:
- Story ID: The claim ID from test.csv
- Prediction: 1 (consistent) or 0 (contradicted)
- Rationale: 1-2 line explanation

================================================================================
SECTION 8: TECHNOLOGIES USED
================================================================================

PYTHON PACKAGES (requirements.txt):
- pathway>=0.4.0           # Document processing (Pathway-based)
- faiss-cpu>=1.7.4         # Vector similarity search
- sentence-transformers    # Text embeddings
- requests                 # HTTP client for Ollama
- tiktoken                 # Token counting
- flask, flask-cors        # Web API framework
- pandas, numpy            # Data manipulation

FRONTEND:
- React 18 + Vite              # Build tool & Framework
- Tailwind CSS                 # Utility-first styling
- Lucide React                 # Iconography
- Recharts                     # Data Visualization

LLM:
- Ollama (mistral:7b-instruct-q4_0 recommended)

================================================================================
SECTION 9: TROUBLESHOOTING
================================================================================

ISSUE: "Ollama not found"
SOLUTION: Install from https://ollama.ai, then run:
   ollama pull mistral:7b-instruct-q4_0

ISSUE: "Module not found" errors
SOLUTION: Ensure virtual environment is activated:
   source .venv/bin/activate
   pip install -r requirements.txt

ISSUE: Pipeline fails at Reasoning stage
SOLUTION: Check Ollama is running:
   ollama serve

ISSUE: Frontend won't start
SOLUTION: Install Node.js dependencies:
   cd frontend && npm install

================================================================================
END OF DOCUMENTATION
================================================================================
